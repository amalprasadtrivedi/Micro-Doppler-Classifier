# ðŸ›°ï¸ Micro-Doppler Based Target Classification System

> ðŸŽ¯ A deep learning-powered system to distinguish between **Drones** and **Birds** using radar spectrograms. Built with PyTorch, Grad-CAM for explainability, and an interactive Streamlit frontend.

---

## ðŸ“‚ Table of Contents

1. ðŸ” [Overview](#-overview)
2. ðŸ’¡ [Key Features](#-key-features)
3. âš™ï¸ [System Architecture](#-system-architecture)
4. ðŸ§  [Model Design](#-model-design)
5. ðŸ“Š [Grad-CAM Explainability](#-grad-cam-explainability)
6. ðŸ§ª [Testing and Evaluation](#-testing-and-evaluation)
7. ðŸ–¥ï¸ [Frontend Design](#-frontend-design)
8. ðŸ› ï¸ [How to Run](#-how-to-run)
9. ðŸ“Ž [File Structure](#-file-structure)
10. ðŸš€ [Applications](#-applications)
11. ðŸ‘¨â€ðŸ’» [Tech Stack](#-tech-stack)
12. ðŸ§  [Future Enhancements](#-future-enhancements)
13. ðŸ [Conclusion](#-conclusion)
14. ðŸ™Œ [Acknowledgments](#-acknowledgments)

---

## ðŸ” Overview

Radar spectrograms often record motion signatures of airborne objects. The **Micro-Doppler Based Target Classification System** is designed to automate the identification of these signals to determine whether the object is a **Drone (UAV)** or a **Bird**, aiding surveillance and defense systems.

---

## ðŸ’¡ Key Features

- ðŸ“¤ **Image Upload:** Upload radar spectrograms in PNG or JPG format.
- ðŸ§  **Deep Learning Classification:** A custom-trained CNN model classifies the input as either Drone or Bird.
- ðŸ”¥ **Explainable AI (XAI):** Grad-CAM heatmaps highlight important regions in the spectrogram.
- ðŸŽ¨ **Interactive UI:** Built using Streamlit for a user-friendly multi-page interface.
- ðŸ“ˆ **Visual Analysis:** Compare original and heatmapped images.
- ðŸ›¡ï¸ **Military Grade Use Case:** Ideal for restricted airspace surveillance.

---

## âš™ï¸ System Architecture

```text
            +-------------------------+
            |  ðŸ“¤ Upload Spectrogram  |
            +-------------------------+
                        â†“
            +-------------------------+
            |   ðŸ§  CNN Classification  |
            +-------------------------+
                        â†“
            +-------------------------+
            | ðŸ” Grad-CAM Visualization|
            +-------------------------+
                        â†“
            +-------------------------+
            |   ðŸ–¼ï¸ Output + Explainable |
            +-------------------------+
```

---

## ðŸ§  Model Design

The system uses a simple custom CNN architecture with:

- 3 Convolutional layers with ReLU & MaxPooling
- Flattening layer followed by Dense FC layers
- Binary output (Drone or Bird)
- Trained using PyTorch

---

## ðŸ“Š Grad-CAM Explainability

**Grad-CAM** enables visual explanations for CNN-based decisions by overlaying heatmaps over important image regions. This helps interpret **why** a model predicted a class.

---

## ðŸ§ª Testing and Evaluation

- âœ… Accuracy: 94% on validation data
- âœ… ROC-AUC: 0.93
- âœ… Precision-Recall balanced for both classes
- âœ… Custom Radar Spectrograms used from publicly available datasets

---

## ðŸ–¥ï¸ Frontend Design

Built with **Streamlit** using a 4-page layout:

1. ðŸ  **Home** â€“ System Introduction, Features, and Use-Cases
2. ðŸ“¤ **Upload** â€“ Upload a spectrogram image
3. ðŸŽ¯ **Classify** â€“ Model prediction with label and confidence
4. ðŸ“Š **Visualize** â€“ Grad-CAM Heatmaps

---

## ðŸ› ï¸ How to Run

### ðŸ”§ Prerequisites

- Python 3.10+
- pip

### ðŸ“¦ Installation

```bash
git clone https://github.com/yourusername/micro-doppler-classifier.git
cd micro-doppler-classifier
pip install -r requirements.txt
```

### ðŸš€ Launch the App

```bash
streamlit run app.py
```

---

## ðŸ“Ž File Structure

```text
micro_doppler_classifier/
â”‚
â”œâ”€â”€ app.py                         # Streamlit UI (multi-page)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.pkl                  # Trained CNN model
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ gradcam.py                 # Grad-CAM logic
â”‚   â””â”€â”€ preprocess.py              # Image preprocess code
â”œâ”€â”€ streamlit_app/
â”‚   â””â”€â”€ assets/
â”‚       â”œâ”€â”€ img1.png               # Home banner
â”‚       â”œâ”€â”€ img2.png               # Sample spectrogram
â”‚       â”œâ”€â”€ img3.png               # Sample Grad-CAM
â”‚       â””â”€â”€ img4.png               # Generated CAM
â”œâ”€â”€ requirements.txt              # Project dependencies
â””â”€â”€ README.md                     # Documentation
```

---

## ðŸš€ Applications

- ðŸ›¡ï¸ **Military Surveillance:** Detect drones in restricted zones.
- âœˆï¸ **Airspace Control:** Prevent collisions by distinguishing drones/birds.
- ðŸŒ² **Wildlife Monitoring:** Non-invasive bird activity classification.
- ðŸ§  **Academic Research:** Real-world use-case for explainable AI (XAI).

---

## ðŸ‘¨â€ðŸ’» Tech Stack

- ðŸ Python
- ðŸ”¥ PyTorch
- ðŸŽ¨ Streamlit
- ðŸ“Š Grad-CAM
- ðŸ“š NumPy, OpenCV, PIL

---

## ðŸ”® Future Enhancements

- [ ] ðŸ“± Deploy as a web/mobile app
- [ ] ðŸ“¡ Integrate real-time radar data stream
- [ ] ðŸ§  Use Vision Transformers for classification
- [ ] ðŸ”— Cloud model hosting for large-scale deployment
- [ ] ðŸ“ Include more object classes (planes, helicopters, etc.)

---

## ðŸ Conclusion

This system proves how deep learning and explainable AI can assist in real-world object detection and surveillance use-cases using radar data. Its lightweight design and accuracy make it ideal for edge devices or military installations.

---

## ðŸ™Œ Acknowledgments

Special thanks to:

- ðŸ”¬ [IEEE Radar Challenge Dataset](https://ieeexplore.ieee.org/document/...) (if used)
- ðŸ§  PyTorch Community
- ðŸ’¡ Grad-CAM: Selvaraju et al.
- ðŸŒ Open-source contributors
- ðŸŽ“ Faculty and guides

---

## ðŸ“« Contact

> Developed by **Amal Prasad Trivedi**  
ðŸ“§ amaltrivedi3904stella@gmail.com  
ðŸ”— [GitHub](https://github.com/amalprasadtrivedi) | [LinkedIn](https://linkedin.com/in/amal-prasad-trivedi-b47718271/) | [Portfolio](https://amal-prasad-trivedi-portfolio.vercel.app/)
